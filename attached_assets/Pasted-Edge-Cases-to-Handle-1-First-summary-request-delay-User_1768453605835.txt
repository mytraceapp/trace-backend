Edge Cases to Handle
1. First summary request = delay

User views history â†’ Wait 2-3 seconds for OpenAI API call
Solution: Show loading spinner, cache thereafter
Alternative: Generate on background when user views history dashboard (fire-and-forget)
2. OpenAI API down

User requests summary, API fails
const summary = fallback || await generateSummary();
// Fallback: "Summary coming soon..." or first 15 words of raw_text

3. User deletes account

Need to hard-delete immediately, not wait 30 days
Solution: Add delete handler:

app.post('/api/user/delete',Â asyncÂ (req,Â res)Â =>Â {Â Â constÂ {Â userIdÂ }Â =Â req.body;Â Â awaitÂ supabaseÂ Â Â Â .from('trace_entries_summary')Â Â Â Â .delete()Â Â Â Â .eq('user_id',Â userId);Â Â //Â Hard-deleteÂ everything});
app.post('/api/user/delete', async (req, res) => {
  const { userId } = req.body;
  await supabase
    .from('trace_entries_summary')
    .delete()
    .eq('user_id', userId);  // Hard-delete everything
});

4. Orphaned device entries

User creates new account on same device
Old device_id entries tied to old user_id
Solution: Cleanup query:

DELETEÂ FROMÂ trace_entries_summaryÂ WHEREÂ user_idÂ ISÂ NULLÂ ANDÂ created_atÂ <Â NOW()Â -Â INTERVALÂ '7Â days';
DELETE FROM trace_entries_summary 
WHERE user_id IS NULL 
AND created_at < NOW() - INTERVAL '7 days';

5. Concurrent summary requests

Two requests for same entryId at same time
Both generate summaries, duplicate work
Solution: Add a lock/transaction
// Check again after fetching
const entry = await fetch();
if (entry.summary_text) return entry.summary_text;  // Already generated
// Then generate...

1. Add a summary_status field


ALTERÂ TABLEÂ trace_entries_summaryADDÂ COLUMNÂ summary_statusÂ VARCHAR(20)Â DEFAULTÂ 'pending'CHECKÂ (summary_statusÂ INÂ ('pending',Â 'generating',Â 'completed',Â 'failed'));

ALTER TABLE trace_entries_summary
ADD COLUMN summary_status VARCHAR(20) DEFAULT 'pending'
CHECK (summary_status IN ('pending', 'generating', 'completed', 'failed'));

Why? Prevents race conditions when generating summaries.

2. Add error handling for failed summaries


//Â IfÂ OpenAIÂ fails,Â markÂ itÂ asÂ failed,Â don'tÂ tryÂ againUPDATEÂ trace_entries_summarySETÂ summary_statusÂ =Â 'failed'WHEREÂ idÂ =Â entryId;
. Consider batch summary generation

At 2 AM (cleanup time), also batch-generate summaries for entries older than 7 days
Spread the cost over night, avoid user-facing delays
Cron job approach:

schedule.scheduleJob('0Â 2Â *Â *Â *',Â asyncÂ ()Â =>Â {Â Â //Â 1.Â CleanupÂ oldÂ entriesÂ Â awaitÂ cleanupOldEntries();Â Â Â Â //Â 2.Â GenerateÂ pendingÂ summariesÂ (bgÂ job)Â Â awaitÂ batchGenerateSummaries();});

4. Add monitoring/logging


console.log('[TRACEÂ SUMMARY]Â Stats:',Â {Â Â cached:Â summariesFromCache,Â Â generated:Â summariesJustGenerated,Â Â failed:Â summariesFailed,Â Â costSavings:Â totalCostReduction});
5. Add user_requested_at timestamp

Track when user last requested summaries
Useful for analytics: "What % of users actually view their history?"
ðŸ’° One More Cost Optimization
Batch summaries at night instead of on-demand:
// Instead of generating summary when user requests it,
// generate summaries for entries from 24+ hours ago automatically

schedule.scheduleJob('0 2 * * *', async () => {
  // Generate summaries for entries older than 1 day
  const oldEntries = await supabase
    .from('trace_entries_summary')
    .select('id, raw_text')
    .is('summary_text', null)
    .lt('created_at', yesterday)
    .limit(100);
  
  for (const entry of oldEntries) {
    // Generate all at once (cheaper batch)
    await generateSummary(entry.id);
  }
});

// When user requests summary, it's already cached
app.post('/api/summary/:entryId', async (req, res) => {
  const entry = await fetch();
  
  if (entry.summary_text) {
    // Already generated by night job
    return res.json({ summary: entry.summary_text });
  }
  
  if (entry.created_at < yesterday) {
    // Should have been generated by now, show cached version
    return res.json({ summary: 'Summary coming soon...' });
  }
  
  // New entry (< 1 day old), generate on-demand
  await generateSummary(entry.id);
});

Result:

99% of summaries are pre-generated (no user delay)
Only new entries (<24hrs) have slight delay
Spreads cost over night (cheaper rates potentially)
ðŸŽ¯ Final Verdict
Overall: 9/10

What I'd do:

âœ… Use the on-demand summary approach (cost-effective)
âœ… Add retention/cleanup policies (GDPR)
âš ï¸ Add the edge case handlers above
ðŸ’¡ Consider batch night-job for 99% cached experience
ðŸ“Š Add monitoring/analytics
This is production-ready, just needs those edge case handlers before deploying.

