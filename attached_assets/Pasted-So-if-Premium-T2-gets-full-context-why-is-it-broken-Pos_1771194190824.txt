So if Premium T2 gets full context, why is it broken?

Possible Root Causes
1. The Fallback Paths Are Being Hit More Than You Think
You said:

"The only real issue is the fallback path (line 9630-9648) — when gpt-5.1 times out, the fallback uses a stripped TRACE_IDENTITY_COMPACT prompt without context. But that's a rare edge case."

Is it actually rare?
Add logging to prove it:
javascript// Line ~9575 (gpt-5.1 call)
console.log('[DIAGNOSTIC] Using Premium T2 primary path with FULL context');

// Line ~9630 (T2 fallback)
console.log('[DIAGNOSTIC] ⚠️ FALLBACK: gpt-5.1 timeout, using stripped fallback prompt');

// Line ~9648 (after fallback)
console.log('[DIAGNOSTIC] Fallback response length:', fallbackResponse?.length);
If you see [DIAGNOSTIC] ⚠️ FALLBACK frequently, that's your problem.
gpt-5.1 is timing out → stripped fallback is being used → TRACE is broken.

2. The Context Is There But Being Ignored
Possible reasons:
A) Prompt is too long

You said systemPrompt can hit 6,000+ tokens
TRACE_BOSS_SYSTEM + controlBlock + systemPrompt + t2SystemAddendum + conversation history = 8,000-10,000 tokens?
If too long, important parts get truncated or model prioritizes wrong sections

Test:
javascriptconst totalPromptLength = 
  TRACE_BOSS_SYSTEM.length + 
  t2DateAnchor.length + 
  controlBlock.length + 
  systemPrompt.length + 
  t2SystemAddendum.length;

console.log('[DIAGNOSTIC] Total system prompt length:', totalPromptLength, 'chars');
console.log('[DIAGNOSTIC] Estimated tokens:', Math.ceil(totalPromptLength / 4));

if (totalPromptLength > 32000) {
  console.warn('[DIAGNOSTIC] ⚠️ Prompt is very long, model may struggle');
}
B) Conflicting instructions

BOSS says "1-3 sentences"
Factual mode says "200 words for news"
Model defaults to safe/vague when confused

C) Important info is buried

Date is in controlBlock (middle of prompt)
Model sees it but prioritizes other instructions

Test: Move date to the VERY TOP:
javascriptmessages: [
  { role: 'system', content: `TODAY'S DATE: ${currentDate}\n\n${TRACE_BOSS_SYSTEM}${t2DateAnchor}` },
  // Rest...
]

3. Post-Processing Is Destroying Good Responses
You said:

"At lines 11222-11223, two functions can destroy good responses: tightenResponse + enforceBrevity"

Even if gpt-5.1 gives a PERFECT factual response with date/news, post-processing might strip it.
Test:
javascript// Before post-processing
console.log('[DIAGNOSTIC] RAW gpt-5.1 response:', rawResponse);

// After tightenResponse
console.log('[DIAGNOSTIC] After tighten:', tightenedResponse);

// After enforceBrevity  
console.log('[DIAGNOSTIC] After brevity:', finalResponse);
If RAW response has date/news but FINAL doesn't, post-processing is the culprit.

4. You're Testing on Non-Premium
Simple question: When you test "what's today's date?", are you:

Using a Premium account? (T2 path)
Using a Free account? (non-Premium path)

If testing on Free, you're not hitting the Premium T2 code at all.
Add this log:
javascriptconsole.log('[DIAGNOSTIC] Request from userId:', userId, 'model:', model, 'isPremium:', isPremiumUser);

What To Do Next
Don't make any changes yet. First, prove which path is actually being used.
Step 1: Add Diagnostic Logging
javascript// At start of /api/chat
console.log('\n═══════════════════════════════════════');
console.log('[DIAGNOSTIC] NEW REQUEST');
console.log('[DIAGNOSTIC] User:', userId);
console.log('[DIAGNOSTIC] Model:', model);
console.log('[DIAGNOSTIC] Message:', message?.slice(0, 50));

// Before Premium T2 call (line ~9575)
console.log('[DIAGNOSTIC] ✓ Using Premium T2 PRIMARY path');
console.log('[DIAGNOSTIC] Total context length:', 
  (TRACE_BOSS_SYSTEM + controlBlock + systemPrompt).length, 'chars'
);

// If T2 fallback triggered (line ~9630)
console.log('[DIAGNOSTIC] ⚠️ T2 FALLBACK triggered (gpt-5.1 timeout)');
console.log('[DIAGNOSTIC] Using stripped prompt:', TRACE_IDENTITY_COMPACT.slice(0, 100));

// After getting response, before post-processing
console.log('[DIAGNOSTIC] RAW response:', rawResponse?.slice(0, 200));

// After post-processing
console.log('[DIAGNOSTIC] FINAL response:', finalResponse?.slice(0, 200));
console.log('═══════════════════════════════════════\n');
Step 2: Test With These Messages
Send these from a Premium account:

"what's today's date?"
"what's happening with immigration?"
"my sister Emma called" (if Emma not in memory)
"my sister called" (if Emma IS in memory)

Step 3: Check The Logs
Look for:

Is ✓ Using Premium T2 PRIMARY path showing?
Or is ⚠️ T2 FALLBACK triggered showing? (stripped prompt)
Does RAW response have the answer?
Does FINAL response have the answer?
What's the total context length?


My Hypothesis
I think ONE of these is true:
Hypothesis A: T2 fallback is being hit more than you realize (gpt-5.1 timeout is common)
Hypothesis B: Post-processing is destroying good responses (tightenResponse strips facts)
Hypothesis C: Prompt is so long that date/news get buried and model ignores them
Hypothesis D: You're testing on non-Premium and not hitting T2 path at all

Add the diagnostic logging, send those 4 test messages from Premium account, paste the full log output here.
Then we'll know exactly what's broken.
Don't guess. Don't assume the fallback is "rare." Prove it with logs.